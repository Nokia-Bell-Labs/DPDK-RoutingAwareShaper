{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37da0e1e",
   "metadata": {},
   "source": [
    "© 2026 Nokia\n",
    "          Licensed under the BSD 3-Clause Clear License\n",
    "          SPDX-License-Identifier: BSD-3-Clause-Clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fcce08-f485-4d6f-a6cf-000278e06ba0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dfc036-e4a5-4461-995d-a61f3f2435cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37befed-2b1a-4608-8854-c74cefbd44f6",
   "metadata": {},
   "source": [
    "### Configure environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d621b02-e934-4c92-97bd-2f0831d9675a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fabrictestbed_extensions.fablib.fablib import FablibManager as fablib_manager\n",
    "fablib = fablib_manager() \n",
    "conf = fablib.show_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ca7467-1ad8-4499-b346-a7315ad7542c",
   "metadata": {},
   "source": [
    "### Define configuration for this experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65703e50-63fe-45cf-a77e-67097a999712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure: host name, nic, cores, ram, disk according to your needs. \n",
    "\n",
    "slice_name= \"wan-inter-site-3-nodes-high-capacity-v2\" + fablib.get_bastion_username()\n",
    "\n",
    "node_conf = [\n",
    " {'name': \"sender\", 'nic': 'NIC_Basic', 'site_name': \"ATLA\", 'cores': 16, 'ram': 32, 'disk': 60, 'image': 'default_ubuntu_22', 'packages': ['iperf3', 'net-tools', 'moreutils','python3']}, \n",
    " {'name': \"router\", 'nic': 'NIC_ConnectX_6', 'site_name': \"ATLA\", 'cores': 16, 'ram': 128, 'disk': 60, 'image': 'default_ubuntu_22', 'packages': ['iperf3', 'net-tools', 'moreutils','python3']}, \n",
    " {'name': \"receiver\", 'nic': 'NIC_ConnectX_6', 'site_name': \"WASH\", 'cores': 16, 'ram': 32, 'disk': 20, 'image': 'default_ubuntu_22', 'packages': ['iperf3', 'net-tools', 'moreutils','python3']}\n",
    "]\n",
    "net_conf = [\n",
    " {\"name\": \"net1\", \"subnet\": \"10.0.2.0/24\", \"nodes\": [{\"name\": \"sender\",   \"addr\": \"10.0.2.100\", 'nic': 'NIC_ConnectX_6'}, {\"name\": \"router\", \"addr\": \"10.0.2.101\", 'nic': 'NIC_ConnectX_6'}]},\n",
    " {\"name\": \"net0\", \"vlan\": 100, \"hops\":\"STAR\", \"bw\": 80, \"subnet\": \"10.0.0.0/24\", \"nodes\": [{\"name\": \"router\",   \"addr\": \"10.0.0.100\", 'nic': 'NIC_ConnectX_6'}, {\"name\": \"receiver\", \"addr\": \"10.0.0.101\", 'nic': 'NIC_ConnectX_6'}]}\n",
    "]\n",
    "\n",
    "route_conf = [\n",
    " {\"addr\": \"10.0.0.0/24\", \"gw\": \"10.0.2.101\", \"nodes\": [\"sender\"]}, \n",
    " {\"addr\": \"10.0.2.0/24\", \"gw\": \"10.0.0.100\", \"nodes\": [\"receiver\"]}\n",
    "]\n",
    "\n",
    "exp_conf = {'cores': sum([ n['cores'] for n in node_conf]), 'nic': sum([len(n['nodes']) for n in net_conf]) }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becddaea-c410-4e09-9cfa-9504032d8738",
   "metadata": {},
   "source": [
    "### Reserve resources\n",
    "\n",
    "Now, we are ready to reserve resources!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a878eaf6-5b30-4d76-b6a1-54d88451a7b0",
   "metadata": {},
   "source": [
    "First, make sure you don’t already have a slice with this name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e897fb-64ae-474c-819f-0081dabe3893",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    slice = fablib.get_slice(slice_name)\n",
    "    print(\"You already have a slice by this name!\")\n",
    "    print(\"If you previously reserved resources, skip to the 'log in to resources' section.\")\n",
    "except:\n",
    "    print(\"You don't have a slice named %s yet.\" % slice_name)\n",
    "    print(\"Continue to the next step to make one.\")\n",
    "    slice = fablib.new_slice(name=slice_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df45406-0765-4d24-8a2d-b98230997f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell sets up the nodes\n",
    "for n in node_conf:\n",
    "    if n.get('host'):  # safe check, no KeyError\n",
    "        slice.add_node(\n",
    "            name=n['name'], site=n['site_name'],\n",
    "            cores=n['cores'], ram=n['ram'],\n",
    "            disk=n['disk'], image=n['image'],\n",
    "            host=n['host']\n",
    "        )\n",
    "    else:\n",
    "        slice.add_node(\n",
    "            name=n['name'], site=n['site_name'],\n",
    "            cores=n['cores'], ram=n['ram'],\n",
    "            disk=n['disk'], image=n['image']\n",
    "        )\n",
    "\n",
    "\n",
    "    slice.get_node(n['name']).add_component(model=n['nic'], name=\"nic1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33af159-6b49-4d26-ad42-ad36e379a09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sender_node = slice.get_node(\"sender\")\n",
    "receiver_node = slice.get_node(\"receiver\")\n",
    "router_node = slice.get_node(\"router\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132bb6f2-1bae-431c-9207-b95709d24089",
   "metadata": {},
   "outputs": [],
   "source": [
    "sender_nic = sender_node.get_component(name=\"nic1\")\n",
    "receiver_nic = receiver_node.get_component(name=\"nic1\")\n",
    "router_nic = router_node.get_component(name=\"nic1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8f76e8-92d3-4f5b-ae65-7199a170b90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, n in enumerate(net_conf):\n",
    "\n",
    "    if n[\"name\"]==\"net1\":\n",
    "        continue\n",
    "    iface_index = 0 \n",
    "\n",
    "    ifaces = [slice.get_node(\"router\").get_component(name=\"nic1\").get_interfaces()[iface_index], slice.get_node(\"receiver\").get_component(name=\"nic1\").get_interfaces()[iface_index]]\n",
    "\n",
    "    for iface in ifaces:\n",
    "        iface.set_mode('auto')\n",
    "        iface.set_vlan(str(n[\"vlan\"]))\n",
    "\n",
    "    ns = slice.add_l2network(name=n[\"name\"], interfaces=ifaces, type='L2PTP')\n",
    "    #ns.set_l2_route_hops(hops=[n[\"hops\"]])\n",
    "    ns.set_bandwidth(n[\"bw\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10825a52-f4e2-405a-bfb7-6b28d73bd743",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, n in enumerate(net_conf):\n",
    "\n",
    "    if n[\"name\"]==\"net0\":\n",
    "        continue\n",
    "    iface_index = 0 \n",
    "\n",
    "    ifaces = [slice.get_node(\"sender\").get_component(name=\"nic1\").get_interfaces()[0], slice.get_node(\"router\").get_component(name=\"nic1\").get_interfaces()[1]]\n",
    "\n",
    "    ns = slice.add_l2network(name=n[\"name\"], interfaces=ifaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd5c7b6-6f98-4ce9-aa15-bd9c97506677",
   "metadata": {},
   "source": [
    "The following cell submits our request to the FABRIC site. The output of this cell will update automatically as the status of our request changes.\n",
    "\n",
    "-   While it is being prepared, the “State” of the slice will appear as “Configuring”.\n",
    "-   When it is ready, the “State” of the slice will change to “StableOK”.\n",
    "\n",
    "You may prefer to walk away and come back in a few minutes (for simple slices) or a few tens of minutes (for more complicated slices with many resources)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43731b1-176c-4cfa-845f-da40ee65a43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61c635b-7bbd-46f5-97a4-3c8ef0d69ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice.get_state()\n",
    "slice.wait_ssh(progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cdc031-ec34-4612-92c6-6beadb0c2415",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice = fablib.get_slice(slice_name)\n",
    "\n",
    "for node in slice.get_nodes():\n",
    "    # Pin all vCPUs for VM to same Numa node as the component\n",
    "    node.pin_cpu(component_name=\"nic1\")\n",
    "    \n",
    "    # User can also pass in the range of the vCPUs to be pinned \n",
    "    #node.pin_cpu(component_name=nic_name, cpu_range_to_pin=\"0-3\")\n",
    "    \n",
    "    # Pin memmory for VM to same Numa node as the components\n",
    "    #node.numa_tune()\n",
    "    try:\n",
    "        node.numa_tune()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Warning: could not pin memory for {node.get_name()}: {e}\")\n",
    "    \n",
    "    # Reboot the VM\n",
    "    node.os_reboot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe0a438-ff22-42b0-b1ae-c8e163a0a128",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice.wait_ssh(progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27011bf1-3c4d-4ed4-ac15-d9a79531e3a2",
   "metadata": {},
   "source": [
    "### Install BBR3 Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81ee28e-3d57-4ff1-b76f-76a028014b59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pkg_list = ['linux-headers-6.4.0+_6.4.0-g6e321d1c986a-5_amd64.deb',\n",
    "            'linux-image-6.4.0+_6.4.0-g6e321d1c986a-5_amd64.deb',\n",
    "            'linux-libc-dev_6.4.0-g6e321d1c986a-5_amd64.deb']\n",
    "\n",
    "cmd_BBRv3 =\"\"\"sudo grub-set-default \"Advanced options for Ubuntu>Ubuntu, with Linux 6.4.0\"\n",
    "sudo grub-mkconfig -o /boot/grub/grub.cfg\n",
    "sudo sed -i 's/^GRUB_DEFAULT=.*/GRUB_DEFAULT=saved/' /etc/default/grub\n",
    "sudo update-grub\n",
    "sudo reboot\"\"\"\n",
    "\n",
    "for pkg in pkg_list:\n",
    "    slice.get_node(name=\"sender\").execute(\"wget https://github.com/ashutoshs25/bbrv3-kernel/raw/main/{packet}\".format(packet=pkg))\n",
    "    slice.get_node(name=\"receiver\").execute(\"wget https://github.com/ashutoshs25/bbrv3-kernel/raw/main/{packet}\".format(packet=pkg))\n",
    "    \n",
    "slice.get_node(name=\"sender\").execute(\"sudo dpkg -i  *.deb\")\n",
    "slice.get_node(name=\"sender\").execute(cmd_BBRv3)\n",
    "\n",
    "slice.get_node(name=\"receiver\").execute(\"sudo dpkg -i  *.deb\")\n",
    "slice.get_node(name=\"receiver\").execute(cmd_BBRv3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1459cd3-3ca1-4f9b-807c-a3d51bd5f90e",
   "metadata": {},
   "source": [
    "### Configure resources\n",
    "\n",
    "Next, we will configure the resources so they are ready to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e896100-2124-4111-a1df-30065030cd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice=fablib.get_slice(slice_name)\n",
    "sender_node = slice.get_node(\"sender\")\n",
    "receiver_node = slice.get_node(\"receiver\")\n",
    "router_node = slice.get_node(\"router\")\n",
    "\n",
    "slice.wait_ssh()\n",
    "\n",
    "for i in slice.get_interfaces():\n",
    "    i.config_vlan_iface()\n",
    "    i.config()\n",
    "\n",
    "for n in slice.get_nodes():\n",
    "    n.config()\n",
    "    #n.execute('sudo node_tools/host_tune_enable_docker.sh', quiet=True, output_file=f\"{n.get_name()}.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e102a8-3471-4bb4-8a8f-5de7dde38785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install packages\n",
    "# this will take a while and will run in background while you do other steps\n",
    "for n in node_conf:\n",
    "    if len(n['packages']):\n",
    "        node = slice.get_node(n['name'])\n",
    "        pkg = \" \".join(n['packages'])\n",
    "        node.execute_thread(\"sudo apt update; sudo DEBIAN_FRONTEND=noninteractive apt -y install %s\" % pkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec7cc05-a03b-422e-a969-868ffef33268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring interfaces up and either assign an address (if there is one) or flush address\n",
    "from ipaddress import ip_address, IPv4Address, IPv4Network\n",
    "\n",
    "for net in net_conf:\n",
    "    for n in net['nodes']:\n",
    "        \n",
    "        # if_name1 = n['name'] + '-' + net['name'] + '-p1'\n",
    "        # if_name2 = n['name'] + '-' + net['name'] + '-p2'\n",
    "\n",
    "        if_name1 = n['name'] + '-' + \"nic1\" + '-p1'\n",
    "        if_name2 = n['name'] + '-' + \"nic1\" + '-p2'\n",
    "        if_name_list=[if_name1, if_name2]\n",
    "        #if_name_list=[if_name1]\n",
    "        \n",
    "        for if_name in if_name_list:            \n",
    "\n",
    "            try:\n",
    "                iface = slice.get_interface(if_name)\n",
    "            except Exception:   \n",
    "                print(f\"{if_name} not found, skipping\")  \n",
    "                continue\n",
    "            \n",
    "            iface.ip_link_up()\n",
    "            if n['addr']:\n",
    "                print(n['addr'])\n",
    "                iface.ip_addr_add(addr=n['addr'], subnet=IPv4Network(net['subnet']))\n",
    "            else:\n",
    "                iface.get_node().execute(\"sudo ip addr flush dev %s\"  % iface.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadfc33d-df2d-42e5-b759-ddd716751d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure all interfaces are brought up\n",
    "for iface in slice.get_interfaces():\n",
    "    iface.ip_link_up()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75daad8e-fbc3-4805-96f9-ffd9336f7758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare a \"hosts\" file that has names and addresses of every node\n",
    "hosts_txt = [ \"%s\\t%s\" % ( n['addr'], n['name'] ) for net in net_conf  for n in net['nodes'] if type(n) is dict and n['addr']]\n",
    "for n in slice.get_nodes():\n",
    "    for h in hosts_txt:\n",
    "        n.execute(\"echo %s | sudo tee -a /etc/hosts\" % h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9e84aa-7580-416d-bdaf-9b54535ae9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable IPv4 forwarding on all nodes\n",
    "for n in slice.get_nodes():\n",
    "    n.execute(\"sudo sysctl -w net.ipv4.ip_forward=1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1e6405-c126-4203-ad78-b8b0d108cbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up static routes\n",
    "for rt in route_conf:\n",
    "   for n in rt['nodes']:\n",
    "       slice.get_node(name=n).ip_route_add(subnet=IPv4Network(rt['addr']), gateway=rt['gw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091e3ef0-665c-48f6-a23a-caf94430ca23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn off segmentation offload on interfaces\n",
    "for iface in slice.get_interfaces():\n",
    "    iface_name = iface.get_device_name()\n",
    "    n = iface.get_node()\n",
    "    offloads = [\"gro\", \"lro\", \"gso\", \"tso\"]\n",
    "    for offload in offloads:\n",
    "        n.execute(\"sudo ethtool -K %s %s off\" % (iface_name, offload))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f399d71-2cf7-4c66-8107-cfea41b626d2",
   "metadata": {},
   "source": [
    "### Validate base network\n",
    "\n",
    "Before we run any experiment, we should check the “base” network - before adding any emulated delay or rate limiting - and make sure that it will not be a limiting factor in the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6267980-bb29-4074-a6c6-a0da93ca84d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check base delay\n",
    "_ = slice.get_node(\"sender\").execute(\"ping -c 5 10.0.0.101\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a7e1b2-193b-4f70-92de-5ead31dd15d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check base capacity (by sending 10 parallel flows, look at their sum throughput)\n",
    "import time\n",
    "_ = slice.get_node(\"receiver\").execute(\"iperf3 -s -1 -D\")\n",
    "time.sleep(5)\n",
    "_ = slice.get_node(\"sender\").execute(\"iperf3 -Z -t 30 -i 10 -C bbr1 -P 10 -c 10.0.0.101\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1101fbe-8d3c-4963-9da0-ef0ba01b4ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# also check Linux kernel version on sender\n",
    "_ = slice.get_node(\"sender\").execute(\"uname -a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ab1ca7-4871-42fa-8f76-9a4f0341fb68",
   "metadata": {},
   "source": [
    "### Draw the network topology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5843fe6-762c-48eb-a5b3-df1c60be9510",
   "metadata": {},
   "source": [
    "The following cell will draw the network topology, for your reference. The interface name and addresses of each experiment interface will be shown on the drawing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a397f553-a2b0-40ea-955b-1141995a3a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_nets = [(n.get_name(), {'color': 'lavender'}) for n in slice.get_l2networks() ]\n",
    "l3_nets = [(n.get_name(), {'color': 'pink'}) for n in slice.get_l3networks() ]\n",
    "hosts   =   [(n.get_name(), {'color': 'lightblue'}) for n in slice.get_nodes()]\n",
    "nodes = l2_nets + l3_nets + hosts\n",
    "ifaces = [iface.toDict() for iface in slice.get_interfaces()]\n",
    "edges = [(iface['network'], iface['node'], \n",
    "          {'label': iface['physical_dev'] + '\\n' + iface['ip_addr'] + '\\n' + iface['mac']}) for iface in ifaces]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d7d02f-68d5-4df0-8345-8f66d8a312bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = [\n",
    "    entry\n",
    "    for entry in ifaces\n",
    "    if entry.get(\"ip_addr\") not in (None, \"None\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c8a0d9-3c2f-451c-a044-4bf24802035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ifaces_new=filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37a1877-5e12-432d-807f-408eb7b08033",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_edges = [\n",
    "    (u, v, attr)\n",
    "    for (u, v, attr) in edges\n",
    "    if (u != 'None' and v != 'None')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd903161-8573-4234-80eb-36b4215013f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_new=clean_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d06cbf5-c583-4a28-af09-5f47ec38c059",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(len(nodes),len(nodes)))\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(nodes)\n",
    "G.add_edges_from(edges_new)\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw(G, pos, node_shape='s',  \n",
    "        node_color=[n[1]['color'] for n in nodes], \n",
    "        node_size=[len(n[0])*400 for n in nodes],  \n",
    "        with_labels=True);\n",
    "nx.draw_networkx_edge_labels(G,pos,\n",
    "                             edge_labels=nx.get_edge_attributes(G,'label'),\n",
    "                             font_color='gray',  font_size=8, rotate=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f93f29-296e-487d-84f3-9574769df1d1",
   "metadata": {},
   "source": [
    "### Log into resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3964cc59-b1b9-45e0-8f21-3a715ad9a0e6",
   "metadata": {},
   "source": [
    "Now, we are finally ready to log in to our resources over SSH! Run the following cells, and observe the table output - you will see an SSH command for each of the resources in your topology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838c7e28-ab43-405c-ab66-d9460139f0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "slice_info = [{'Name': n.get_name(), 'SSH command': n.get_ssh_command()} for n in slice.get_nodes()]\n",
    "pd.DataFrame(slice_info).set_index('Name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdce8e11-fcf1-449c-9b5f-68064c41b6d9",
   "metadata": {},
   "source": [
    "Now, you can open an SSH session on any of the resources as follows:\n",
    "\n",
    "-   in Jupyter, from the menu bar, use File \\> New \\> Terminal to open a new terminal.\n",
    "-   copy an SSH command from the table, and paste it into the terminal. (Note that each SSH command is a single line, even if the display wraps the text to a second line! When you copy and paste it, paste it all together.)\n",
    "\n",
    "You can repeat this process (open several terminals) to start a session on each resource. Each terminal session will have a tab in the Jupyter environment, so that you can easily switch between them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46085413-8d41-46bc-b118-2c0fadcdd481",
   "metadata": {},
   "source": [
    "### Tune Hosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f269111-cec8-4d1b-9f68-119eb1de6741",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for node in slice.get_nodes():\n",
    "    node.upload_directory('/home/fabric/work/Internship-work/node_tools','.')\n",
    "    node.execute('chmod +x node_tools/host_tune.sh')\n",
    "    node.execute('sudo sysctl net.ipv4.tcp_available_congestion_control')\n",
    "    node.execute('sudo ./node_tools/host_tune.sh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62651e51-4073-4377-98a0-96142c5c2528",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For DPDK\n",
    "router_node.upload_directory('/home/fabric/work/DPDK/node_toolsv2','.')\n",
    "router_node.execute('chmod +x node_toolsv2/install.sh')\n",
    "router_node.execute('sudo ./node_toolsv2/install.sh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a4b4bd-f3c0-408d-8aa7-46fda747b9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For DPDK\n",
    "router_node.execute('chmod +x node_toolsv2/grub.sh')\n",
    "router_node.execute('chmod +x node_toolsv2/apply_vfio_settings.sh')\n",
    "\n",
    "stdout, stderr = router_node.execute(f\"sudo node_toolsv2/grub.sh {router_node.get_ram()}\")\n",
    "stdout, stderr = router_node.execute(\"sudo node_toolsv2/apply_vfio_settings.sh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341023e2-286d-41cf-9172-8e17b1122792",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "router_node.execute(\"pip install gdown\")\n",
    "router_node.execute(\"~/.local/bin/gdown https://drive.google.com/uc?id=1Cy0gDm-44sKhaEXyEeuKQSx2di7DO1Xd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902f169f-46cb-4fff-93ca-40faaa29a873",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "router_node.execute(\"sudo mount -o ro,loop /home/ubuntu/MLNX_OFED_LINUX-24.10-3.2.5.0-ubuntu22.04-x86_64.iso /mnt/\")\n",
    "router_node.execute(\"sudo /mnt/mlnxofedinstall --force\") \n",
    "router_node.execute(\"sudo /etc/init.d/openibd restart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82d0cdb-c217-42d4-88ac-cebf1b0953c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "router_node.execute(\"sudo apt-get update\")\n",
    "router_node.execute(\"sudo apt-get install -y libibverbs-dev rdma-core ibverbs-utils pkg-config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706d1066-947d-446c-bb0c-5fc8b533d4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_node.execute(\"sudo reboot\")\n",
    "# wait for all nodes to come back up\n",
    "slice.wait_ssh(progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70903cf1-c37a-4f02-933f-a922334c2bc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# necessary for DPDK\n",
    "cmds = \"\"\"\n",
    "sudo apt-get update\n",
    "sudo apt-get install -y libelf-dev libssl-dev libbsd-dev libarchive-dev libfdt-dev libjansson-dev\n",
    "\"\"\"\n",
    "router_node.execute(cmds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a09eaf-5a63-42fd-a679-b90f99bc7c90",
   "metadata": {},
   "source": [
    "### Configure the network capacity and delay\n",
    "\n",
    "In this section, we configure the bottleneck link to have a 40Mbps capacity and 10ms delay. We will initialize the queue size to 32 BDP (although we will change this later)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9fabd5-1df0-4c95-8e82-0d5ef455c47f",
   "metadata": {},
   "source": [
    "Then, we validate the new network setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9e49d3-78e5-4404-98ed-14dd31c653b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check base delay\n",
    "_ = slice.get_node(\"sender\").execute(\"ping -c 5 receiver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c14723d-c4d4-48d0-8cd7-8f547283c9ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check base capacity (by sending 10 parallel flows, look at their sum throughput)\n",
    "import time\n",
    "_ = slice.get_node(\"receiver\").execute(\"iperf3 -s -1 -D\")\n",
    "time.sleep(5)\n",
    "_ = slice.get_node(\"sender\").execute(\"iperf3 -t 60 -i 10 -P 10 -C cubic -c receiver\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2607a360-2af1-4b25-a76a-f173c2b84211",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6306e448-c6e7-4e35-a3d1-a3a2cab0a5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sudo apt update\n",
    "# sudo apt install -y build-essential gcc make libssl-dev libsctp-dev\n",
    "\n",
    "# # 1) remove any old local install that might shadow the new one\n",
    "# sudo rm -f /usr/local/bin/iperf3\n",
    "# sudo rm -f /usr/local/lib/libiperf*\n",
    "# sudo rm -f /usr/local/include/iperf_api.h\n",
    "# sudo ldconfig\n",
    "\n",
    "\n",
    "# cd /tmp\n",
    "# curl -LO https://github.com/esnet/iperf/releases/download/3.19.1/iperf-3.19.1.tar.gz\n",
    "# tar -xf iperf-3.19.1.tar.gz\n",
    "# cd iperf-3.19.1\n",
    "\n",
    "# ./configure\n",
    "# make -j\"$(nproc)\"\n",
    "# sudo make install\n",
    "# sudo ldconfig\n",
    "\n",
    "# hash -r                        \n",
    "# which iperf3                  \n",
    "# iperf3 --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddcb357-f269-4377-8cca-6aab2c4f9b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sudo ethtool -g enp7s0np0\n",
    "# sudo ethtool -G enp7s0np0 rx 8192 tx 8192\n",
    "\n",
    "#  ethtool -S enp7s0np0 | grep rx_out_of_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27b9657-5679-4066-b853-fe1fe990796c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_drop_check_command(expname: str) -> str:\n",
    "    \"\"\"\n",
    "    Build a self-contained bash command that:\n",
    "      - auto-discovers interfaces (physical + VLANs on them)\n",
    "      - checks ip-link, ethtool (real drop/error counters), tc qdisc/class\n",
    "      - writes and tees output to /home/ubuntu/drop_check_<expname>.log\n",
    "      - exits 0 if clean, 1 if any drops/errors found\n",
    "    \"\"\"\n",
    "    # Pass expname via a shell var to avoid Python string formatting conflicts\n",
    "    prefix = f'EXP=\"{expname}\"; '\n",
    "    body = r'''\n",
    "LOGFILE=\"/home/ubuntu/drop_check_${EXP}.log\"\n",
    "exec > >(tee -a \"$LOGFILE\") 2>&1\n",
    "\n",
    "echo \"=== Drop Check Started at $(date) ===\"\n",
    "\n",
    "# --- Auto-discover interfaces (physical + VLANs on them) ---\n",
    "mapfile -t PHYS_IFACES < <(for d in /sys/class/net/*; do\n",
    "  dev=$(basename \"$d\")\n",
    "  [[ \"$dev\" == \"lo\" ]] && continue\n",
    "  [[ -e \"$d/device\" ]] || continue\n",
    "  echo \"$dev\"\n",
    "done)\n",
    "\n",
    "mapfile -t VLAN_IFACES < <(ip -d -o link show type vlan 2>/dev/null | awk -F': ' '{print $2}' | while read -r pair; do\n",
    "  ifname=\"${pair%%@*}\"; lower=\"${pair##*@}\"\n",
    "  for p in \"${PHYS_IFACES[@]}\"; do\n",
    "    if [[ \"$lower\" == \"$p\" ]]; then echo \"$ifname\"; break; fi\n",
    "  done\n",
    "done)\n",
    "\n",
    "declare -A seen\n",
    "IFACES=()\n",
    "for x in \"${PHYS_IFACES[@]}\" \"${VLAN_IFACES[@]}\"; do\n",
    "  [[ -n \"$x\" && -d \"/sys/class/net/$x\" && -z \"${seen[$x]}\" ]] && IFACES+=(\"$x\") && seen[$x]=1\n",
    "done\n",
    "\n",
    "echo \"Discovered interfaces: ${IFACES[*]}\"\n",
    "ok=true\n",
    "\n",
    "# --- Checkers ---\n",
    "check_ip_link() {\n",
    "  ip -s link show dev \"$1\" 2>/dev/null | awk '\n",
    "    /RX:/ { getline; split($0,a); rx_err=a[3]+0; rx_drop=a[4]+0 }\n",
    "    /TX:/ { getline; split($0,b); tx_err=b[3]+0; tx_drop=b[4]+0 }\n",
    "    END {\n",
    "      if (rx_err || rx_drop || tx_err || tx_drop)\n",
    "        printf \"ip_link: RXerr=%d RXdrop=%d TXerr=%d TXdrop=%d\\n\", rx_err, rx_drop, tx_err, tx_drop\n",
    "    }'\n",
    "}\n",
    "\n",
    "check_ethtool() {\n",
    "  local IFACE=\"$1\"\n",
    "  local BASE=\"${IFACE%%.*}\"\n",
    "  (sudo ethtool -S \"$IFACE\" 2>/dev/null || sudo ethtool -S \"$BASE\" 2>/dev/null) | \\\n",
    "  awk -F':' '\n",
    "    {\n",
    "      k=$1; v=$2; gsub(/^[ \\t]+|[ \\t]+$/, \"\", v); lk=tolower(k)\n",
    "      # Only counters that indicate *real* loss/errors; print only if >0\n",
    "      if (lk ~ /(rx_out_of_buffer|rx_dropped|tx_dropped|rx_errors|tx_errors|no_buffer|overflow|rx_missed_errors|discard|no_desc|fifo_errors|crc_errors|length_errors)/) {\n",
    "        if ((v+0) > 0) printf \"ethtool: %s %s\\n\", k, v+0\n",
    "      }\n",
    "    }'\n",
    "}\n",
    "\n",
    "check_tc_qdisc_class() {\n",
    "  local IFACE=\"$1\"\n",
    "  sudo tc -s qdisc show dev \"$IFACE\" 2>/dev/null | \\\n",
    "    awk '/Sent/ { if (match($0,/dropped +([0-9]+)/,m) && m[1]>0) print \"qdisc: \" $0 }'\n",
    "  sudo tc -s class show dev \"$IFACE\" 2>/dev/null | \\\n",
    "    awk '/Sent/ { if (match($0,/dropped +([0-9]+)/,m) && m[1]>0) print \"class: \" $0 }'\n",
    "}\n",
    "\n",
    "# --- Run checks ---\n",
    "for IFACE in \"${IFACES[@]}\"; do\n",
    "  echo \"=== Checking $IFACE ===\"\n",
    "  DROPS=$(\n",
    "    check_ip_link \"$IFACE\"\n",
    "    check_ethtool \"$IFACE\"\n",
    "    check_tc_qdisc_class \"$IFACE\"\n",
    "  )\n",
    "  if [[ -z \"$DROPS\" ]]; then\n",
    "    echo \"✅ No drops on $IFACE\"\n",
    "  else\n",
    "    ok=false\n",
    "    echo \"❌ Drops/errors detected on $IFACE:\"\n",
    "    echo \"$DROPS\"\n",
    "  fi\n",
    "  echo\n",
    "done\n",
    "\n",
    "if $ok; then\n",
    "  echo \"✅✅ All interfaces clean — No drops anywhere.\"\n",
    "  rc=0\n",
    "else\n",
    "  echo \"⚠️ Some interfaces show drops/errors above.\"\n",
    "  rc=1\n",
    "fi\n",
    "\n",
    "echo \"=== Drop Check Finished at $(date) ===\"\n",
    "echo \"Results saved to $LOGFILE\"\n",
    "exit $rc\n",
    "'''\n",
    "    return prefix + body\n",
    "\n",
    "\n",
    "def run_drop_check(node, expname: str):\n",
    "    \"\"\"Execute the drop-check on a given node with a chosen experiment name.\"\"\"\n",
    "    cmd = build_drop_check_command(expname)\n",
    "    return node.execute(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a23d73-7f60-452f-8814-b9fc3edaa8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_drop_check_command(expname: str) -> str:\n",
    "    \"\"\"\n",
    "    Build a self-contained bash command that:\n",
    "      - auto-discovers interfaces (physical + VLANs on them)\n",
    "      - checks ip-link, ethtool (real drop/error counters), tc qdisc/class\n",
    "      - checks per-CPU softnet backlog drops and (if available) nstat TCP/IP counters\n",
    "      - writes and tees output to /home/ubuntu/drop_check_<expname>.log\n",
    "      - exits 0 if clean, 1 if any drops/errors found\n",
    "    \"\"\"\n",
    "    prefix = f'EXP=\"{expname}\"; '\n",
    "    body = r'''\n",
    "LOGFILE=\"/home/ubuntu/drop_check_${EXP}.log\"\n",
    "exec > >(tee -a \"$LOGFILE\") 2>&1\n",
    "\n",
    "echo \"=== Drop Check Started at $(date) ===\"\n",
    "\n",
    "# --- Auto-discover interfaces (physical + VLANs on them) ---\n",
    "mapfile -t PHYS_IFACES < <(for d in /sys/class/net/*; do\n",
    "  dev=$(basename \"$d\")\n",
    "  [[ \"$dev\" == \"lo\" ]] && continue\n",
    "  [[ -e \"$d/device\" ]] || continue   # only devices backed by hardware\n",
    "  echo \"$dev\"\n",
    "done)\n",
    "\n",
    "mapfile -t VLAN_IFACES < <(ip -d -o link show type vlan 2>/dev/null | awk -F': ' '{print $2}' | while read -r pair; do\n",
    "  ifname=\"${pair%%@*}\"; lower=\"${pair##*@}\"\n",
    "  for p in \"${PHYS_IFACES[@]}\"; do\n",
    "    if [[ \"$lower\" == \"$p\" ]]; then echo \"$ifname\"; break; fi\n",
    "  done\n",
    "done)\n",
    "\n",
    "declare -A seen\n",
    "IFACES=()\n",
    "for x in \"${PHYS_IFACES[@]}\" \"${VLAN_IFACES[@]}\"; do\n",
    "  [[ -n \"$x\" && -d \"/sys/class/net/$x\" && -z \"${seen[$x]}\" ]] && IFACES+=(\"$x\") && seen[$x]=1\n",
    "done\n",
    "\n",
    "echo \"Discovered interfaces: ${IFACES[*]}\"\n",
    "ok=true\n",
    "\n",
    "# --- Helpers ---\n",
    "\n",
    "check_ip_link() {\n",
    "  ip -s link show dev \"$1\" 2>/dev/null | awk '\n",
    "    /RX:/ { getline; split($0,a); rx_err=a[3]+0; rx_drop=a[4]+0 }\n",
    "    /TX:/ { getline; split($0,b); tx_err=b[3]+0; tx_drop=b[4]+0 }\n",
    "    END {\n",
    "      if (rx_err || rx_drop || tx_err || tx_drop)\n",
    "        printf \"ip_link: RXerr=%d RXdrop=%d TXerr=%d TXdrop=%d\\n\", rx_err, rx_drop, tx_err, tx_drop\n",
    "    }'\n",
    "}\n",
    "\n",
    "check_ethtool() {\n",
    "  local IFACE=\"$1\"\n",
    "  local BASE=\"${IFACE%%.*}\"\n",
    "  (sudo ethtool -S \"$IFACE\" 2>/dev/null || sudo ethtool -S \"$BASE\" 2>/dev/null) | \\\n",
    "  awk -F':' '\n",
    "    {\n",
    "      k=$1; v=$2; gsub(/^[ \\t]+|[ \\t]+$/, \"\", v); lk=tolower(k)\n",
    "      # Print only if >0; focus on true loss/error indicators.\n",
    "      if (lk ~ /(rx_out_of_buffer|rx_dropped|tx_dropped|rx_errors|tx_errors|no_buffer|overflow|rx_missed_errors|discard|no_desc|fifo_errors|crc_errors|length_errors|rx_discards_phy|rx_prio[0-9]+_discards)/) {\n",
    "        if ((v+0) > 0) printf \"ethtool: %s %s\\n\", k, v+0\n",
    "      }\n",
    "    }'\n",
    "}\n",
    "\n",
    "check_tc_qdisc_class() {\n",
    "  local IFACE=\"$1\"\n",
    "  sudo tc -s qdisc show dev \"$IFACE\" 2>/dev/null | \\\n",
    "    awk '/Sent/ { if (match($0,/dropped +([0-9]+)/,m) && m[1]>0) print \"qdisc: \" $0 }'\n",
    "  sudo tc -s class show dev \"$IFACE\" 2>/dev/null | \\\n",
    "    awk '/Sent/ { if (match($0,/dropped +([0-9]+)/,m) && m[1]>0) print \"class: \" $0 }'\n",
    "}\n",
    "\n",
    "check_softnet_stat() {\n",
    "  # Snapshot (no delta): column 2 per line (hex) = softnet backlog drops on that CPU.\n",
    "  i=0\n",
    "  while read -r line; do\n",
    "    i=$((i+1)); set -- $line\n",
    "    drops=$((16#$2))\n",
    "    if (( drops > 0 )); then\n",
    "      echo \"softnet: CPU$((i-1)) backlog_drops(total) = $drops\"\n",
    "    fi\n",
    "  done < /proc/net/softnet_stat\n",
    "}\n",
    "\n",
    "check_nstat() {\n",
    "  # Optional: shows TCP/IP stack counters if iproute2's nstat is installed.\n",
    "  if ! command -v nstat >/dev/null 2>&1; then\n",
    "    return 0\n",
    "  fi\n",
    "  nstat -az 2>/dev/null | awk '\n",
    "    $1 ~ /^(IpInDiscards|IpInErrors|TcpInErrs|TcpRetransSegs)$/ && $2>0 {\n",
    "      printf \"nstat: %s = %s\\n\", $1, $2\n",
    "    }'\n",
    "}\n",
    "\n",
    "# --- Run per-interface checks ---\n",
    "for IFACE in \"${IFACES[@]}\"; do\n",
    "  echo \"=== Checking $IFACE ===\"\n",
    "  DROPS=$(\n",
    "    check_ip_link \"$IFACE\"\n",
    "    check_ethtool \"$IFACE\"\n",
    "    check_tc_qdisc_class \"$IFACE\"\n",
    "  )\n",
    "  if [[ -z \"$DROPS\" ]]; then\n",
    "    echo \"✅ No drops on $IFACE\"\n",
    "  else\n",
    "    ok=false\n",
    "    echo \"❌ Drops/errors detected on $IFACE:\"\n",
    "    echo \"$DROPS\"\n",
    "  fi\n",
    "  echo\n",
    "done\n",
    "\n",
    "# --- System-wide checks ---\n",
    "echo \"=== Checking softnet backlog drops (per-CPU) ===\"\n",
    "SN=$(check_softnet_stat)\n",
    "if [[ -z \"$SN\" ]]; then\n",
    "  echo \"✅ No softnet backlog drops\"\n",
    "else\n",
    "  ok=false\n",
    "  echo \"❌ Softnet drops detected:\"\n",
    "  echo \"$SN\"\n",
    "fi\n",
    "echo\n",
    "\n",
    "echo \"=== Checking nstat (TCP/IP stack counters) ===\"\n",
    "NS=$(check_nstat)\n",
    "if [[ -z \"$NS\" ]]; then\n",
    "  echo \"✅ nstat clean or not installed\"\n",
    "else\n",
    "  ok=false\n",
    "  echo \"❌ Stack-level counters nonzero:\"\n",
    "  echo \"$NS\"\n",
    "fi\n",
    "echo\n",
    "\n",
    "# --- Result ---\n",
    "if $ok; then\n",
    "  echo \"✅✅ All interfaces clean — No drops anywhere.\"\n",
    "  rc=0\n",
    "else\n",
    "  echo \"⚠️ Some drops/errors detected above.\"\n",
    "  rc=1\n",
    "fi\n",
    "\n",
    "echo \"=== Drop Check Finished at $(date) ===\"\n",
    "echo \"Results saved to $LOGFILE\"\n",
    "exit $rc\n",
    "'''\n",
    "    return prefix + body\n",
    "\n",
    "\n",
    "def run_drop_check(node, expname: str):\n",
    "    \"\"\"Execute the drop-check on a given node with a chosen experiment name.\"\"\"\n",
    "    cmd = build_drop_check_command(expname)\n",
    "    return node.execute(cmd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7beb8d9-6669-45b6-86f6-7d4832ef5995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "METRICS = [\n",
    "    \"rx_out_of_buffer\",\n",
    "    \"rx_discards_phy\",\n",
    "    \"rx_prio_discards\",\n",
    "    \"ip_rxdrop\",\n",
    "    \"ip_txdrop\",\n",
    "    \"tc_qdisc_drop\",\n",
    "    \"tc_class_drop\",\n",
    "    \"retrans\",\n",
    "]\n",
    "\n",
    "\n",
    "def parse_drop_log(log_text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Parse a single node's drop_check log into host-level counters.\n",
    "\n",
    "    - Tracks per-interface stats under the current \"=== Checking IFACE ===\".\n",
    "    - Groups interfaces by base name (e.g., enp7s0np0 and enp7s0np0.100 → base 'enp7s0np0').\n",
    "    - For each base, takes the *max* across its interfaces (to avoid double-counting VLAN mirrors).\n",
    "    - Sums across base interfaces to get host-level totals.\n",
    "    - 'retrans' (TcpRetransSegs) is node-wide, not per-interface.\n",
    "    \"\"\"\n",
    "    iface_counters = {}  # iface -> metric -> value\n",
    "    host_retrans = 0\n",
    "    current_iface = None\n",
    "\n",
    "    def ensure_iface(iface):\n",
    "        if iface not in iface_counters:\n",
    "            iface_counters[iface] = {\n",
    "                \"rx_out_of_buffer\": 0,\n",
    "                \"rx_discards_phy\": 0,\n",
    "                \"rx_prio_discards\": 0,\n",
    "                \"ip_rxdrop\": 0,\n",
    "                \"ip_txdrop\": 0,\n",
    "                \"tc_qdisc_drop\": 0,\n",
    "                \"tc_class_drop\": 0,\n",
    "            }\n",
    "\n",
    "    for raw in log_text.splitlines():\n",
    "        line = raw.strip()\n",
    "\n",
    "        # Detect interface section\n",
    "        m = re.match(r\"=== Checking (\\S+) ===\", line)\n",
    "        if m:\n",
    "            current_iface = m.group(1)\n",
    "            ensure_iface(current_iface)\n",
    "            continue\n",
    "\n",
    "        # nstat (host-wide)\n",
    "        m = re.match(r\"nstat:\\s+TcpRetransSegs\\s+=\\s+(\\d+)\", line)\n",
    "        if m:\n",
    "            host_retrans = int(m.group(1))\n",
    "            continue\n",
    "\n",
    "        if not current_iface:\n",
    "            continue  # ignore lines outside an interface section\n",
    "\n",
    "        # ip -s link RX/TX drops\n",
    "        m = re.match(r\"ip_link: RXerr=\\d+ RXdrop=(\\d+) TXerr=\\d+ TXdrop=(\\d+)\", line)\n",
    "        if m:\n",
    "            rx_drop = int(m.group(1))\n",
    "            tx_drop = int(m.group(2))\n",
    "            ensure_iface(current_iface)\n",
    "            iface_counters[current_iface][\"ip_rxdrop\"] += rx_drop\n",
    "            iface_counters[current_iface][\"ip_txdrop\"] += tx_drop\n",
    "            continue\n",
    "\n",
    "        # ethtool stats\n",
    "        m = re.match(r\"ethtool:\\s+(\\S+)\\s+(\\d+)\", line)\n",
    "        if m:\n",
    "            key = m.group(1)\n",
    "            val = int(m.group(2))\n",
    "            ensure_iface(current_iface)\n",
    "            if key == \"rx_out_of_buffer\":\n",
    "                # absolute counter\n",
    "                iface_counters[current_iface][\"rx_out_of_buffer\"] = val\n",
    "            elif key == \"rx_discards_phy\":\n",
    "                iface_counters[current_iface][\"rx_discards_phy\"] = val\n",
    "            elif re.match(r\"rx_prio\\d+_discards\", key):\n",
    "                # could be multiple priorities; sum them within the iface\n",
    "                iface_counters[current_iface][\"rx_prio_discards\"] += val\n",
    "            continue\n",
    "\n",
    "        # tc qdisc drops\n",
    "        m = re.search(r\"qdisc: .*dropped (\\d+)\", line)\n",
    "        if m:\n",
    "            ensure_iface(current_iface)\n",
    "            iface_counters[current_iface][\"tc_qdisc_drop\"] += int(m.group(1))\n",
    "            continue\n",
    "\n",
    "        # tc class drops\n",
    "        m = re.search(r\"class: .*dropped (\\d+)\", line)\n",
    "        if m:\n",
    "            ensure_iface(current_iface)\n",
    "            iface_counters[current_iface][\"tc_class_drop\"] += int(m.group(1))\n",
    "            continue\n",
    "\n",
    "    # --- Group by base interface (e.g., enp7s0np0 vs enp7s0np0.100) ---\n",
    "    grouped = {}  # base_iface -> metric -> value (max across variants)\n",
    "    for iface, stats in iface_counters.items():\n",
    "        base = iface.split(\".\")[0]\n",
    "        if base not in grouped:\n",
    "            grouped[base] = {k: 0 for k in stats.keys()}\n",
    "        for k, v in stats.items():\n",
    "            if v > grouped[base][k]:\n",
    "                grouped[base][k] = v\n",
    "\n",
    "    # --- Sum across base interfaces to get host-level totals ---\n",
    "    total = {k: 0 for k in METRICS}\n",
    "    for base, stats in grouped.items():\n",
    "        for k in stats:\n",
    "            total[k] += stats[k]\n",
    "\n",
    "    total[\"retrans\"] = host_retrans\n",
    "    return total\n",
    "\n",
    "\n",
    "def print_counter_diff(label: str, before: dict, after: dict):\n",
    "    print(f\"\\n=== DIFF for {label} ===\")\n",
    "    for k in METRICS:\n",
    "        b = before.get(k, 0)\n",
    "        a = after.get(k, 0)\n",
    "        diff = a - b\n",
    "        print(f\"{k:18s}: before={b:8d}  after={a:8d}  diff={diff:+d}\")\n",
    "    print(\"====================================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7b1a5a-a42a-422f-9169-5c799f81dcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_node = slice.get_node(\"router\")\n",
    "sender_node = slice.get_node(\"sender\")\n",
    "receiver_node = slice.get_node(\"receiver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa7e2dd-ddb2-459b-a066-8c1287dfce17",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_ingress_iface = router_node.get_interface(network_name = \"net1\")\n",
    "router_ingress_name = router_ingress_iface.get_device_name()\n",
    "router_egress_iface  = router_node.get_interface(network_name = \"net0\")\n",
    "router_egress_name = router_egress_iface.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6e877d-f849-48a5-ad34-1c22c7129255",
   "metadata": {},
   "outputs": [],
   "source": [
    "sender_egress_iface = sender_node.get_interface(network_name = \"net1\")\n",
    "sender_egress_name = sender_egress_iface.get_device_name()\n",
    "\n",
    "receiver_ingress_iface  = receiver_node.get_interface(network_name = \"net0\")\n",
    "receiver_ingress_name = receiver_ingress_iface.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa3c418-73a0-4f83-b340-5022b7d71294",
   "metadata": {},
   "outputs": [],
   "source": [
    "sender_node.execute(\"uname -r\")\n",
    "receiver_node.execute(\"uname -r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bb4f40-28ad-4bd3-b62f-d6e3af7de64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sender_node.execute(\"iperf3 --version\")\n",
    "receiver_node.execute(\"iperf3 --version\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e217899b-1d4c-4002-8ec4-9d6e7b724063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate full factorial experiment\n",
    "import itertools\n",
    "\n",
    "exp_factors = {\n",
    "    'n_bdp': [8],  # n x bandwidth delay product (BDP)\n",
    "    'btl_capacity': [80], #in Gbps \n",
    "    'burst':[13000],\n",
    "    'base_rtt': [13], # in ms \n",
    "    #'aqm': ['FIFO', 'single-queue-FQ', 'pie_drop', 'Codel_drop', 'Codel', 'FQ', 'FQ_Codel', 'FQ_Codel_L4S', 'DualPI2'],\n",
    "    'aqm': ['FIFO'],\n",
    "    'ecn_threshold': [52], # in ms\n",
    "    'ecn': [1],  # 0: noecn, 1: ecn, 3: accecn #'rx_L4S_ecn': [0, 1, 3]\n",
    "    'cc': [\"bbr1\"], # prague, bbr2, cubic, bbr\n",
    "    'flow_number': [10], # flow per file\n",
    "    'duration': [120],\n",
    "    'file_size':[5], # in GB\n",
    "    'trial': [1,2,3,4,5,6,7,8,9,10] # it means total 10 trials here.\n",
    "}\n",
    "factor_names = [k for k in exp_factors]\n",
    "factor_lists = list(itertools.product(*exp_factors.values()))\n",
    "\n",
    "exp_lists = []\n",
    "\n",
    "seen_combinations = set()\n",
    "\n",
    "# Removing ECN factor from FIFO bottleneck because it does not support ECN. This could be done also for pie_drop and codel_drop but we have not done.\n",
    "# Removing the cases where ECN Threshold is less than or equal to the buffer size in time, these cases are not meaningful in practice.\n",
    "\n",
    "for factor_l in factor_lists:\n",
    "    temp_dict = dict(zip(factor_names, factor_l))\n",
    "    if temp_dict['n_bdp'] * temp_dict['base_rtt'] >= temp_dict['ecn_threshold']:\n",
    "        if temp_dict['aqm'] == 'FIFO':\n",
    "            del temp_dict['ecn_threshold']\n",
    "        # Convert dict to a frozenset for set operations\n",
    "        fs = frozenset(temp_dict.items())\n",
    "    \n",
    "        if fs not in seen_combinations:\n",
    "            seen_combinations.add(fs)\n",
    "            exp_lists.append(temp_dict)\n",
    "\n",
    "data_dir = slice_name + '-same-site'\n",
    "\n",
    "print(\"Number of experiments:\",len(exp_lists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706aef54-e0ab-4951-bdcc-43b1763c716f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sender_node.execute('sudo sysctl -w net.core.wmem_default=$((16*1024*1024))')\n",
    "# sender_node.execute('sudo sysctl -w net.core.rmem_default=$((16*1024*1024))')\n",
    "\n",
    "\n",
    "# sender_node.execute('sudo sysctl -w net.core.wmem_max=$((512*1024*1024))')\n",
    "# sender_node.execute('sudo sysctl -w net.core.rmem_max=$((512*1024*1024))')\n",
    "\n",
    "# sender_node.execute('sudo sysctl -w net.ipv4.tcp_wmem=\"$((6*1024*1024)) $((16*1024*1024)) $((256*1024*1024))\"')\n",
    "# sender_node.execute('sudo sysctl -w net.ipv4.tcp_rmem=\"$((6*1024*1024)) $((16*1024*1024)) $((256*1024*1024))\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5deee2-5baa-45f3-9fb7-681651d4342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Socket / TCP memory ceilings (match table's \"2147483647\") ---\n",
    "sender_node.execute('sudo sysctl -w net.core.wmem_max=2147483647')\n",
    "sender_node.execute('sudo sysctl -w net.core.rmem_max=2147483647')\n",
    "\n",
    "# tcp_mem is in PAGES (low / pressure / high) – set very high as in the table\n",
    "sender_node.execute('sudo sysctl -w net.ipv4.tcp_mem=\"2147483647 2147483647 2147483647\"')\n",
    "\n",
    "# TCP autotune ranges (min, default, max in BYTES) – max to 2 GB per table\n",
    "sender_node.execute('sudo sysctl -w net.ipv4.tcp_wmem=\"4096 87380 2147483647\"')\n",
    "sender_node.execute('sudo sysctl -w net.ipv4.tcp_rmem=\"4096 87380 2147483647\"')\n",
    "\n",
    "sender_node.execute('sudo sysctl -w net.core.wmem_default=$((16*1024*1024))')\n",
    "sender_node.execute('sudo sysctl -w net.core.rmem_default=$((16*1024*1024))')\n",
    "\n",
    "# --- Other kernel knobs from the table ---\n",
    "sender_node.execute('sudo sysctl -w net.core.netdev_max_backlog=250000')\n",
    "sender_node.execute('sudo sysctl -w net.ipv4.tcp_mtu_probing=1')\n",
    "sender_node.execute('sudo sysctl -w net.ipv4.tcp_no_metrics_save=1')\n",
    "sender_node.execute('sudo sysctl -w net.ipv4.tcp_timestamps=1')\n",
    "sender_node.execute('sudo sysctl -w net.core.default_qdisc=fq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9d06e7-c07a-4ed4-b952-0acb5e0fcd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# receiver_node.execute('sudo sysctl -w net.core.wmem_default=$((16*1024*1024))')\n",
    "# receiver_node.execute('sudo sysctl -w net.core.rmem_default=$((16*1024*1024))')\n",
    "\n",
    "# receiver_node.execute('sudo sysctl -w net.core.wmem_max=$((512*1024*1024))')\n",
    "# receiver_node.execute('sudo sysctl -w net.core.rmem_max=$((512*1024*1024))')\n",
    "\n",
    "# receiver_node.execute('sudo sysctl -w net.ipv4.tcp_wmem=\"$((6*1024*1024)) $((16*1024*1024)) $((256*1024*1024))\"')\n",
    "# receiver_node.execute('sudo sysctl -w net.ipv4.tcp_rmem=\"$((6*1024*1024)) $((16*1024*1024)) $((256*1024*1024))\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65df628e-2d4a-4950-bd3d-1b49f65995d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Socket / TCP memory ceilings (match table's \"2147483647\") ---\n",
    "receiver_node.execute('sudo sysctl -w net.core.wmem_max=2147483647')\n",
    "receiver_node.execute('sudo sysctl -w net.core.rmem_max=2147483647')\n",
    "\n",
    "# tcp_mem is in PAGES (low / pressure / high) – set very high as in the table\n",
    "receiver_node.execute('sudo sysctl -w net.ipv4.tcp_mem=\"2147483647 2147483647 2147483647\"')\n",
    "\n",
    "# TCP autotune ranges (min, default, max in BYTES) – max to 2 GB per table\n",
    "receiver_node.execute('sudo sysctl -w net.ipv4.tcp_wmem=\"4096 87380 2147483647\"')\n",
    "receiver_node.execute('sudo sysctl -w net.ipv4.tcp_rmem=\"4096 87380 2147483647\"')\n",
    "\n",
    "receiver_node.execute('sudo sysctl -w net.core.wmem_default=$((16*1024*1024))')\n",
    "receiver_node.execute('sudo sysctl -w net.core.rmem_default=$((16*1024*1024))')\n",
    "\n",
    "# --- Other kernel knobs from the table ---\n",
    "receiver_node.execute('sudo sysctl -w net.core.netdev_max_backlog=250000')\n",
    "receiver_node.execute('sudo sysctl -w net.ipv4.tcp_mtu_probing=1')\n",
    "receiver_node.execute('sudo sysctl -w net.ipv4.tcp_no_metrics_save=1')\n",
    "receiver_node.execute('sudo sysctl -w net.ipv4.tcp_timestamps=1')\n",
    "receiver_node.execute('sudo sysctl -w net.core.default_qdisc=fq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e3f35a-8421-4bc4-b729-0d6ee3e560a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the buffer sizes\n",
    "sender_node.execute(\"sysctl net.core.rmem_max net.core.wmem_max net.ipv4.tcp_rmem net.ipv4.tcp_wmem\")\n",
    "receiver_node.execute(\"sysctl net.core.rmem_max net.core.wmem_max net.ipv4.tcp_rmem net.ipv4.tcp_wmem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b17c91-92c1-4d6d-b971-d9cdcf122b96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "# make sure that you are using correct kernel. \n",
    "\n",
    "# make sure BBR is available # this is BBRv3 in BBRv3 kernel, otherwise it is BBRv1. \n",
    "# In BBRv3 kernel, BBRv1 is bbr1 not bbr.\n",
    "\n",
    "\n",
    "#sender_node.execute(\"sudo modprobe tcp_bbr\") \n",
    "#receiver_node.execute(\"sudo modprobe tcp_bbr\")\n",
    "\n",
    "old_flow_number=0\n",
    "\n",
    "for exp in exp_lists:\n",
    "\n",
    "    if exp['aqm']==\"FIFO\":\n",
    "        exp['ecn_threshold']=0\n",
    "    \n",
    "        \n",
    "    name = str(exp['cc'])+\"_\" +str(exp['aqm']) +\"_\" +str(exp['ecn']) +\"_\" +str(exp['ecn_threshold']) +\"_\" +str(exp['n_bdp'])+\"_\"+str(exp['btl_capacity'])+\"_\" +str(exp['burst'])+\"_\"+str(exp['base_rtt'])+\"_\"+ str(exp['flow_number']) +\"_\" +str(exp['duration'])+\"_\"+str(exp['file_size']) +\"_\"+str(exp['ssthresh_bdp_level'])+\"_\"+str(exp['reset_timer'])+\"_\"+str(exp['trial'])\n",
    "    name_tx= name+ \".txt\"\n",
    "    \n",
    "    \n",
    "    stdout_tx_json, stderr_tx_json = receiver_node.execute(\"ls \" + name_tx, quiet=True) \n",
    "    \n",
    "\n",
    "    if len(stdout_tx_json):\n",
    "        print(\"Already have \" + name_tx + \", skipping\")\n",
    "\n",
    "    elif len(stderr_tx_json):\n",
    "\n",
    "        print(\"Running:\",exp)\n",
    "\n",
    "        sender_node.execute(\"sudo modprobe tcp_\" + exp['cc'])\n",
    "\n",
    "        if exp['cc'] ==\"bbr3\":\n",
    "            \n",
    "            exp['cc'] = \"bbr\"\n",
    "            \n",
    "\n",
    "        receiver_address=\"10.0.0.101\"\n",
    "    \n",
    "            \n",
    "        # output = receiver_node.execute(\"ethtool -S enp7s0np0 | grep rx_out_of_buffer\")[0].strip()\n",
    "        # print(f\"receiver enp7s0np0: {output}\")\n",
    "\n",
    "        # output = sender_node.execute(\"ethtool -S enp7s0 | grep rx_out_of_buffer\")[0].strip()\n",
    "        # print(f\"sender enp7s0: {output}\")\n",
    "\n",
    "        # output = router_node.execute(\"ethtool -S enp7s0np0 | grep rx_out_of_buffer\")[0].strip()\n",
    "        # print(f\"router enp7s0np0: {output}\")\n",
    "\n",
    "        # output = router_node.execute(\"ethtool -S enp8s0np1 | grep rx_out_of_buffer\")[0].strip()\n",
    "        # print(f\"router enp8s0np1: {output}\")\n",
    "\n",
    "        # run_drop_check(router_node, name+\"_before\")\n",
    "        # run_drop_check(sender_node, name+\"_before\")\n",
    "        # run_drop_check(receiver_node, name+\"_before\")\n",
    "\n",
    "        \n",
    "\n",
    "        receiver_node.execute(\"sudo modprobe tcp_\" + exp['cc'])\n",
    "        receiver_node.execute(\"sudo sysctl -w net.ipv4.tcp_congestion_control=\" + exp['cc'])\n",
    "\n",
    "        receiver_node.execute(\"sudo sysctl -w net.ipv4.tcp_ecn=\"+str(exp['ecn'])) \n",
    "        \n",
    "        # fixed values\n",
    "        btl_limit    = int(1000*exp['n_bdp']*exp['btl_capacity']*1000*exp['base_rtt']/8) # limit of the bottleneck, n_bdp x BDP in bytes \n",
    "        packet_number=int(btl_limit/9000)+1\n",
    "\n",
    "        # set router buffer limit \n",
    "        bdp_kbyte = exp['base_rtt']*exp['btl_capacity']*1000/8\n",
    "        btl_limit_ss=int(1000*1000*exp['btl_capacity']*(exp['base_rtt'])/8)\n",
    "\n",
    "        btl_limit_ss=(btl_limit_ss/9000)\n",
    "\n",
    "        ssthreshinit=btl_limit_ss # BDP initialization\n",
    "\n",
    "        \n",
    "        sender_node.execute(\"sudo sysctl -w net.ipv4.tcp_congestion_control=\" + exp['cc'])\n",
    "        sender_node.execute(\"sudo sysctl -w net.ipv4.tcp_ecn=\"+str(exp['ecn'])) \n",
    "\n",
    "        cmds_prefix = '''\n",
    "            sudo tc qdisc del dev {iface} root\n",
    "            sudo tc qdisc replace dev {iface} root handle 1: htb default 3\n",
    "            sudo tc class add dev {iface} parent 1: classid 1:3 htb rate {capacity}Gbit ceil {capacity}Gbit burst {burst}kb cburst {burst}kb quantum 9000\n",
    "            '''.format(iface=router_egress_name, capacity=exp['btl_capacity'], burst=exp['burst'])\n",
    "\n",
    "        cmds_specific_initial = \"sudo tc qdisc replace dev {iface} parent 1:3 handle 3: \".format(iface=router_egress_name)\n",
    "  \n",
    "        cmds_specific = {\n",
    "        'FIFO': \"bfifo limit {buffer}\".format(buffer=btl_limit),\n",
    "        #'FQ': \"fq limit 41667 flow_limit 41667 ce_threshold {threshold}ms\".format(packet_limit=min(1000000,packet_number), threshold=exp.get('ecn_threshold', 0)),\n",
    "        'FQ': \"fq limit {packet_limit} flow_limit {packet_limit} ce_threshold {threshold}ms\".format(packet_limit=packet_number, threshold=exp.get('ecn_threshold', 0)),\n",
    "        'single-queue-FQ': \"fq limit {packet_limit} flow_limit {packet_limit} orphan_mask 0 quantum 9000 initial_quantum 9000 ce_threshold {threshold}ms\".format(packet_limit=packet_number, threshold=exp.get('ecn_threshold', 0)),\n",
    "        'Codel': \"codel limit {packet_limit} target {target}ms interval 100ms ecn\".format(packet_limit=packet_number, target=exp.get('ecn_threshold', 0)),\n",
    "        'FQ_new': \"fq limit {packet_limit} flow_limit {packet_limit} ce_threshold {threshold}ms\".format(packet_limit=min(1000000,packet_number), threshold=exp.get('ecn_threshold', 0)),\n",
    "        'FQ_no_ecn': \"fq limit {packet_limit} flow_limit {packet_limit}\".format(packet_limit=min(10000,packet_number)),\n",
    "        'FQ_Codel': \"fq_codel limit {packet_limit} target {target}ms interval 100ms ecn\".format(packet_limit=packet_number, target=exp.get('ecn_threshold', 0)),\n",
    "        #'DualPI2': \"dualpi2 limit {packet_limit} alpha 0 beta 0 target 1000ms step_thresh {threshold}ms\".format(packet_limit=packet_number, threshold=exp.get('ecn_threshold', 0))\n",
    "        'DualPI2': \"dualpi2 limit {packet_limit} target {threshold}ms\".format(packet_limit=packet_number, threshold=exp.get('ecn_threshold', 0))\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "        cmds_aqm = {key: cmds_specific_initial + cmd for key, cmd in cmds_specific.items()}\n",
    "\n",
    "        router_node.execute(f\"sudo tc qdisc del dev {router_egress_name} root\")\n",
    "\n",
    "        \n",
    "        router_node.execute(cmds_prefix)\n",
    "        router_node.execute(cmds_aqm[ exp['aqm'] ])\n",
    "\n",
    "\n",
    "        # clean up\n",
    "        receiver_node.execute(\"sudo killall iperf3\")\n",
    "        sender_node.execute(\"sudo killall iperf3\")\n",
    "        \n",
    "        time.sleep(5) \n",
    "        \n",
    "        # start an iperf3 receiver\n",
    "        receiver_node.execute_thread(f\"iperf3 -s -1 -i 0.1 -p 5201 -fm --logfile \" + name + \".txt\")\n",
    "    \n",
    "        time.sleep(10) \n",
    "    \n",
    "        ss_tx_script=\"rm -f {flow}-ss.txt; start_time=$(date +%s); while true; do ss --no-header -eipmn dst 10.0.0.101:5201 | ts '%.s' | tee -a {flow}-ss.txt; current_time=$(date +%s); elapsed_time=$((current_time - start_time));  if [ $elapsed_time -ge {duration} ]; then break; fi; sleep 0.1; done;\"      \n",
    "\n",
    "        queue_script=\"sleep 4; rm {flow}-queue.txt; start_time=$(date +%s); while true; do tc -p -s -d qdisc show dev {iface} | tr -d \\'\\n\\' | ts '%.s' | tee -a {flow}-queue.txt; echo \\\"\\\" | tee -a {flow}-queue.txt; current_time=$(date +%s); elapsed_time=$((current_time - start_time));  if [ $elapsed_time -ge {duration} ]; then break; fi; sleep 0.01; done;\"\n",
    "        \n",
    "\n",
    "\n",
    "        # set time for transmission\n",
    "        sender_node.execute_thread(f\"sleep 1; iperf3 -Z -c {receiver_address} -p 5201 -fm -t \" + str(exp['duration']) + \" -C \" + exp[\"cc\"] + \" -P \"+str(exp['flow_number']) +\" -J > \"+ name+\".json\")\n",
    "\n",
    "        # set data size for transmission\n",
    "        #sender_node.execute(\"sleep 1; iperf3 -c receiver -p 5201 -n \" + str(exp['file_size']) + \"G\"+ \" -C \" + exp[\"cc\"] + \" -P \"+str(exp['flow_number']) +\" -J > \"+ name+\".json\")\n",
    "\n",
    "        time.sleep(exp['duration'] + 10)\n",
    "\n",
    "\n",
    "        receiver_node.execute(f\"tail -n 1 {name}.txt\")\n",
    "\n",
    "\n",
    "        # run_drop_check(router_node, name)\n",
    "        # run_drop_check(sender_node, name)\n",
    "        # run_drop_check(receiver_node, name)\n",
    "\n",
    "\n",
    "        #         # --- ROUTER before/after ---\n",
    "        # before_router_log = router_node.execute(f\"cat /home/ubuntu/drop_check_{name}_before.log\")[0]\n",
    "        # after_router_log  = router_node.execute(f\"cat /home/ubuntu/drop_check_{name}.log\")[0]\n",
    "        \n",
    "        # before_router = parse_drop_log(before_router_log)\n",
    "        # after_router  = parse_drop_log(after_router_log)\n",
    "        \n",
    "        # # --- SENDER before/after ---\n",
    "        # before_sender_log = sender_node.execute(f\"cat /home/ubuntu/drop_check_{name}_before.log\")[0]\n",
    "        # after_sender_log  = sender_node.execute(f\"cat /home/ubuntu/drop_check_{name}.log\")[0]\n",
    "        \n",
    "        # before_sender = parse_drop_log(before_sender_log)\n",
    "        # after_sender  = parse_drop_log(after_sender_log)\n",
    "        \n",
    "        # # --- RECEIVER before/after ---\n",
    "        # before_receiver_log = receiver_node.execute(f\"cat /home/ubuntu/drop_check_{name}_before.log\")[0]\n",
    "        # after_receiver_log  = receiver_node.execute(f\"cat /home/ubuntu/drop_check_{name}.log\")[0]\n",
    "        \n",
    "        # before_receiver = parse_drop_log(before_receiver_log)\n",
    "        # after_receiver  = parse_drop_log(after_receiver_log)\n",
    "        \n",
    "        # # --- Print comparisons ---\n",
    "        # print_counter_diff(\"ROUTER\",   before_router,   after_router)\n",
    "        # print_counter_diff(\"SENDER\",   before_sender,   after_sender)\n",
    "        # print_counter_diff(\"RECEIVER\", before_receiver, after_receiver)\n",
    "\n",
    "    \n",
    "print(\"done\")\n",
    "\n",
    "# output = receiver_node.execute(\"ethtool -S enp7s0np0 | grep rx_out_of_buffer\")[0].strip()\n",
    "# print(f\"receiver enp7s0np0: {output}\")\n",
    "\n",
    "# output = sender_node.execute(\"ethtool -S enp7s0 | grep rx_out_of_buffer\")[0].strip()\n",
    "# print(f\"sender enp7s0: {output}\")\n",
    "\n",
    "# output = router_node.execute(\"ethtool -S enp7s0np0 | grep rx_out_of_buffer\")[0].strip()\n",
    "# print(f\"router enp7s0np0: {output}\")\n",
    "\n",
    "# output = router_node.execute(\"ethtool -S enp8s0np1 | grep rx_out_of_buffer\")[0].strip()\n",
    "# print(f\"router enp8s0np1: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64536bbe-8931-4fd2-a2aa-5a8b78a2691a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "# make sure that you are using correct kernel. \n",
    "\n",
    "\n",
    "# make sure BBR is available # this is BBRv3 in BBRv3 kernel, otherwise it is BBRv1. \n",
    "# In BBRv3 kernel, BBRv1 is bbr1 not bbr.\n",
    "\n",
    "\n",
    "#sender_node.execute(\"sudo modprobe tcp_bbr\") \n",
    "#receiver_node.execute(\"sudo modprobe tcp_bbr\")\n",
    "\n",
    "old_flow_number=0\n",
    "\n",
    "for exp in exp_lists:\n",
    "\n",
    "    if exp['aqm']==\"FIFO\":\n",
    "        exp['ecn_threshold']=0\n",
    "\n",
    "\n",
    "    if exp['cc']==\"prague\":\n",
    "        exp['ecn']=3\n",
    "        \n",
    "    name = str(exp['cc'])+\"_\" +str(exp['aqm']) +\"_\" +str(exp['ecn']) +\"_\" +str(exp['ecn_threshold']) +\"_\" +str(exp['n_bdp'])+\"_\"+str(exp['btl_capacity'])+\"_\"+str(exp['base_rtt'])+\"_\"+ str(exp['flow_number']) +\"_\" +str(exp['duration'])+\"_\"+str(exp['file_size']) +\"_\"+str(exp['ssthresh_bdp_level'])+\"_\"+str(exp['reset_timer'])+\"_\"+str(exp['trial'])\n",
    "    name_tx= name+ \".txt\"\n",
    "    \n",
    "    \n",
    "    stdout_tx_json, stderr_tx_json = receiver_node.execute(\"ls \" + name_tx, quiet=True) \n",
    "    \n",
    "\n",
    "    if len(stdout_tx_json):\n",
    "        print(\"Already have \" + name_tx + \", skipping\")\n",
    "\n",
    "    elif len(stderr_tx_json):\n",
    "\n",
    "        print(\"Running:\",exp)\n",
    "\n",
    "        receiver_address=\"10.0.0.101\"\n",
    "\n",
    "\n",
    "        # output = receiver_node.execute(\"ethtool -S enp7s0np0 | grep rx_out_of_buffer\")[0].strip()\n",
    "        # print(f\"receiver enp7s0np0: {output}\")\n",
    "\n",
    "        # output = sender_node.execute(\"ethtool -S enp7s0 | grep rx_out_of_buffer\")[0].strip()\n",
    "        # print(f\"sender enp8s0np1: {output}\")\n",
    "\n",
    "        # run_drop_check(router_node, name+\"_before\")\n",
    "        # run_drop_check(sender_node, name+\"_before\")\n",
    "        # run_drop_check(receiver_node, name+\"_before\")\n",
    "\n",
    "        if exp['cc'] ==\"bbr3\":\n",
    "            \n",
    "            exp['cc'] = \"bbr\"\n",
    "\n",
    "        sender_node.execute(\"sudo modprobe tcp_\" + exp['cc'])\n",
    "\n",
    "        receiver_node.execute(\"sudo modprobe tcp_\" + exp['cc'])\n",
    "        receiver_node.execute(\"sudo sysctl -w net.ipv4.tcp_congestion_control=\" + exp['cc'])\n",
    "\n",
    "        receiver_node.execute(\"sudo sysctl -w net.ipv4.tcp_ecn=\"+str(exp['ecn'])) \n",
    "        \n",
    "        # fixed values\n",
    "        btl_limit    = int(1000*exp['n_bdp']*exp['btl_capacity']*1000*exp['base_rtt']/8) # limit of the bottleneck, n_bdp x BDP in bytes \n",
    "        packet_number=int(btl_limit/1500)+1\n",
    "\n",
    "        # set router buffer limit \n",
    "        bdp_kbyte = exp['base_rtt']*exp['btl_capacity']*1000/8\n",
    "\n",
    "        btl_limit_ss=int(1000*1000*exp['btl_capacity']*(exp['base_rtt'])/8)\n",
    "\n",
    "        \n",
    "        btl_limit_ss=(btl_limit_ss/1500)\n",
    "\n",
    "        \n",
    "        ssthreshinit=btl_limit_ss # BDP initialization\n",
    "    \n",
    "        \n",
    "        sender_node.execute(\"sudo sysctl -w net.ipv4.tcp_congestion_control=\" + exp['cc'])\n",
    "        sender_node.execute(\"sudo sysctl -w net.ipv4.tcp_ecn=\"+str(exp['ecn'])) \n",
    "\n",
    "        \n",
    "        cmds_specific = {\n",
    "        'FIFO': \"bfifo limit {buffer}\".format(buffer=btl_limit),\n",
    "        #'FQ': \"fq limit 41667 flow_limit 41667 ce_threshold {threshold}ms\".format(packet_limit=min(1000000,packet_number), threshold=exp.get('ecn_threshold', 0)),\n",
    "        'FQ': \"fq limit {packet_limit} flow_limit {packet_limit} ce_threshold {threshold}ms\".format(packet_limit=packet_number, threshold=exp.get('ecn_threshold', 0)),\n",
    "        'single-queue-FQ': \"fq limit {packet_limit} flow_limit {packet_limit} orphan_mask 0 ce_threshold {threshold}ms\".format(packet_limit=packet_number, threshold=exp.get('ecn_threshold', 0)),\n",
    "        'FQ_new': \"fq limit {packet_limit} flow_limit {packet_limit} ce_threshold {threshold}ms\".format(packet_limit=min(1000000,packet_number), threshold=exp.get('ecn_threshold', 0)),\n",
    "        'FQ_no_ecn': \"fq limit {packet_limit} flow_limit {packet_limit}\".format(packet_limit=min(10000,packet_number)),\n",
    "        'FQ_Codel': \"fq_codel limit {packet_limit} target {target}ms interval 100ms ecn\".format(packet_limit=packet_number, target=exp.get('ecn_threshold', 0)),\n",
    "        'DualPI2': \"dualpi2 limit {packet_limit} alpha 0 beta 0 target 1000ms step_thresh {threshold}ms\".format(packet_limit=packet_number, threshold=exp.get('ecn_threshold', 0))\n",
    "        }\n",
    "\n",
    "        # clean up\n",
    "        receiver_node.execute(\"sudo killall iperf3\")\n",
    "        sender_node.execute(\"sudo killall iperf3\")\n",
    "        \n",
    "        time.sleep(5) \n",
    "\n",
    "\n",
    "        router_node.execute_thread(f\"sudo bash /home/ubuntu/DPDK/v22.11.10/dpdk-stable-22.11.10/DaaS/PoCPhase3/tm10/tm10_scripts/run_tm10.sh {int(exp['btl_capacity']*1000)} user_01_tm01_1flow.cfg 1 > output-{name}.log 2>&1\") \n",
    "\n",
    "        time.sleep(1) \n",
    "\n",
    "        router_node.execute_thread(f\"sudo bash /home/ubuntu/DPDK/v22.11.10/dpdk-stable-22.11.10/DaaS/PoCPhase3/tm10/tm10_scripts/run_tm10-v2.sh {int(exp['btl_capacity']*1000)} user_01_tm-rev.cfg 1 > output-reverse-{name}.log 2>&1\")\n",
    "\n",
    "        time.sleep(1)\n",
    "        \n",
    "        # start an iperf3 receiver\n",
    "        receiver_node.execute_thread(f\"iperf3 -s -1 -i 0.1 -p 33000 -fm --logfile \" + name + \".txt\")\n",
    "\n",
    "    \n",
    "        time.sleep(10) \n",
    "    \n",
    "      \n",
    "\n",
    "        sender_node.execute_thread(\"sleep 1; iperf3 -Z -c 10.0.0.101 -p 33000 --cport 30001 -t \" + str(exp['duration'])+ \" -C \" + exp[\"cc\"] + \" -P \"+str(exp['flow_number']) +\" -J > \"+ name+\".json\")\n",
    "        \n",
    "\n",
    "        time.sleep(exp['duration'] + 10)\n",
    "\n",
    "        router_node.execute(\"sudo pkill -f tm10\")\n",
    "        router_node.execute(\"pkill -f 'mpstat -P ALL 1'\")\n",
    "\n",
    "        router_node.execute(\"sudo rm -f /mnt/huge/rte*map_*\")\n",
    "\n",
    "        router_node.execute(\"sudo rm -f /mnt/huge1G/rte*map_*\")\n",
    "\n",
    "        router_node.execute(\"sudo rm -f /dev/hugepages/rte*map_*\")\n",
    "\n",
    "        receiver_node.execute(\"sudo killall iperf3\")\n",
    "        sender_node.execute(\"sudo killall iperf3\")\n",
    "\n",
    "\n",
    "        receiver_node.execute(f\"tail -n 1 {name}.txt\")\n",
    "\n",
    "        # run_drop_check(router_node, name)\n",
    "        # run_drop_check(sender_node, name)\n",
    "        # run_drop_check(receiver_node, name)\n",
    "\n",
    "\n",
    "        #         # --- ROUTER before/after ---\n",
    "        # before_router_log = router_node.execute(f\"cat /home/ubuntu/drop_check_{name}_before.log\")[0]\n",
    "        # after_router_log  = router_node.execute(f\"cat /home/ubuntu/drop_check_{name}.log\")[0]\n",
    "        \n",
    "        # before_router = parse_drop_log(before_router_log)\n",
    "        # after_router  = parse_drop_log(after_router_log)\n",
    "        \n",
    "        # # --- SENDER before/after ---\n",
    "        # before_sender_log = sender_node.execute(f\"cat /home/ubuntu/drop_check_{name}_before.log\")[0]\n",
    "        # after_sender_log  = sender_node.execute(f\"cat /home/ubuntu/drop_check_{name}.log\")[0]\n",
    "        \n",
    "        # before_sender = parse_drop_log(before_sender_log)\n",
    "        # after_sender  = parse_drop_log(after_sender_log)\n",
    "        \n",
    "        # # --- RECEIVER before/after ---\n",
    "        # before_receiver_log = receiver_node.execute(f\"cat /home/ubuntu/drop_check_{name}_before.log\")[0]\n",
    "        # after_receiver_log  = receiver_node.execute(f\"cat /home/ubuntu/drop_check_{name}.log\")[0]\n",
    "        \n",
    "        # before_receiver = parse_drop_log(before_receiver_log)\n",
    "        # after_receiver  = parse_drop_log(after_receiver_log)\n",
    "        \n",
    "        # # --- Print comparisons ---\n",
    "        # print_counter_diff(\"ROUTER\",   before_router,   after_router)\n",
    "        # print_counter_diff(\"SENDER\",   before_sender,   after_sender)\n",
    "        # print_counter_diff(\"RECEIVER\", before_receiver, after_receiver)\n",
    "        \n",
    "\n",
    "        time.sleep(25) \n",
    "      \n",
    "print(\"done\")\n",
    "\n",
    "\n",
    "# output = router_node.execute(\"ethtool -S enp8s0np1 | grep rx_out_of_buffer\")[0].strip()\n",
    "# print(f\"router enp8s0np1: {output}\")\n",
    "\n",
    "# output = router_node.execute(\"ethtool -S enp7s0np0 | grep rx_out_of_buffer\")[0].strip()\n",
    "# print(f\"router enp7s0np0: {output}\")\n",
    "\n",
    "# output = receiver_node.execute(\"ethtool -S enp8s0np1 | grep rx_out_of_buffer\")[0].strip()\n",
    "# print(f\"receiver enp7s0np0: {output}\")\n",
    "\n",
    "# output = sender_node.execute(\"ethtool -S enp7s0 | grep rx_out_of_buffer\")[0].strip()\n",
    "# print(f\"sender enp7s0np0: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c286f9-dfcc-40ec-938a-f6e1d97ca717",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_node.execute(\"sudo pkill -f tm10\")\n",
    "router_node.execute(\"pkill -f 'mpstat -P ALL 1'\")\n",
    "\n",
    "router_node.execute(\"sudo rm -f /mnt/huge/rte*map_*\")\n",
    "\n",
    "router_node.execute(\"sudo rm -f /mnt/huge1G/rte*map_*\")\n",
    "\n",
    "router_node.execute(\"sudo rm -f /dev/hugepages/rte*map_*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48416a8e-d995-4320-ac76-34755cf0c3f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " # --- ROUTER before/after ---\n",
    "before_router_log = router_node.execute(f\"cat /home/ubuntu/drop_check_{name}_before.log\")[0]\n",
    "after_router_log  = router_node.execute(f\"cat /home/ubuntu/drop_check_{name}.log\")[0]\n",
    "\n",
    "before_router = parse_drop_log(before_router_log)\n",
    "after_router  = parse_drop_log(after_router_log)\n",
    "\n",
    "# --- SENDER before/after ---\n",
    "before_sender_log = sender_node.execute(f\"cat /home/ubuntu/drop_check_{name}_before.log\")[0]\n",
    "after_sender_log  = sender_node.execute(f\"cat /home/ubuntu/drop_check_{name}.log\")[0]\n",
    "\n",
    "before_sender = parse_drop_log(before_sender_log)\n",
    "after_sender  = parse_drop_log(after_sender_log)\n",
    "\n",
    "# --- RECEIVER before/after ---\n",
    "before_receiver_log = receiver_node.execute(f\"cat /home/ubuntu/drop_check_{name}_before.log\")[0]\n",
    "after_receiver_log  = receiver_node.execute(f\"cat /home/ubuntu/drop_check_{name}.log\")[0]\n",
    "\n",
    "before_receiver = parse_drop_log(before_receiver_log)\n",
    "after_receiver  = parse_drop_log(after_receiver_log)\n",
    "\n",
    "# --- Print comparisons ---\n",
    "print_counter_diff(\"ROUTER\",   before_router,   after_router)\n",
    "print_counter_diff(\"SENDER\",   before_sender,   after_sender)\n",
    "print_counter_diff(\"RECEIVER\", before_receiver, after_receiver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8091cf5-2e85-4847-818e-3083bae7bda3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cmds_py_install = '''\n",
    "            sudo apt -y install python3-pip\n",
    "            pip install numpy\n",
    "            pip install matplotlib\n",
    "            pip install pandas\n",
    "            '''\n",
    "\n",
    "sender_node.execute(cmds_py_install)\n",
    "receiver_node.execute(cmds_py_install)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d357d4-31b5-435a-9b82-624539b5dbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir=\"exp-results\"\n",
    "\n",
    "sender_node.execute('mkdir '+data_dir)\n",
    "sender_node.execute('mv *.json '+ data_dir)\n",
    "\n",
    "receiver_node.execute('mkdir '+data_dir)\n",
    "receiver_node.execute('mv *.txt '+ data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5156a2-4b53-41db-ad90-d5f2fe1e1faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sender_node.upload_file(\"/home/fabric/work/Internship-work/analysis_simple.py\", f\"/home/ubuntu/{data_dir}/analysis.py\")\n",
    "\n",
    "sender_node.execute(f'python3 /home/ubuntu/{data_dir}/analysis.py')\n",
    "\n",
    "outname1 = f\"sender-throughput.json\"\n",
    "\n",
    "# remote source stays the same, local filename changes\n",
    "sender_node.download_file(f\"/home/fabric/work/Internship-work/L2P2P-QoS/{outname1}\", f\"/home/ubuntu/{data_dir}/throughput_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8565080c-b2f2-425e-85ad-337000571ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# ----------------------------\n",
    "# Config (paper-ready styling)\n",
    "# ----------------------------\n",
    "plt.rcParams.update({\n",
    "    \"font.size\": 10,\n",
    "    \"axes.labelsize\": 10,\n",
    "    \"axes.titlesize\": 10,\n",
    "    \"xtick.labelsize\": 9,\n",
    "    \"ytick.labelsize\": 9,\n",
    "    \"legend.fontsize\": 9,\n",
    "    \"pdf.fonttype\": 42,   # TrueType fonts in PDF\n",
    "    \"ps.fonttype\": 42,\n",
    "    \"axes.linewidth\": 0.8,\n",
    "})\n",
    "\n",
    "INPUT_JSON = \"sender-throughput.json\"\n",
    "OUT_PDF = \"sender_throughput_groups.pdf\"\n",
    "OUT_PNG = \"sender_throughput_groups.png\"  # optional raster copy\n",
    "\n",
    "# Define suffix ranges and (ordered) labels\n",
    "groups = [\n",
    "    (\"DPDK Shaping\", range(250, 255)),\n",
    "    (\"DPDK Forwarding\", range(350, 355)),\n",
    "    (\"Linux forwarding\", range(450, 455)),\n",
    "    (\"HTB Shaping\", range(550, 555)),\n",
    "]\n",
    "\n",
    "# ----------------------------\n",
    "# Load + group data\n",
    "# ----------------------------\n",
    "with open(INPUT_JSON, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "group_values = {name: [] for name, _ in groups}\n",
    "\n",
    "for key, value in data.items():\n",
    "    try:\n",
    "        suffix = int(str(key).split(\"_\")[-1])\n",
    "    except (ValueError, AttributeError):\n",
    "        continue\n",
    "\n",
    "    for group_name, suffix_range in groups:\n",
    "        if suffix in suffix_range:\n",
    "            group_values[group_name].append(float(value) / 1000.0)  # Gb/s\n",
    "            break\n",
    "\n",
    "# Compute stats (skip empty groups)\n",
    "labels = []\n",
    "means = []\n",
    "mins_ = []\n",
    "maxs_ = []\n",
    "ns = []\n",
    "\n",
    "for group_name, _ in groups:\n",
    "    vals = np.array(group_values[group_name], dtype=float)\n",
    "    if vals.size == 0:\n",
    "        continue\n",
    "    labels.append(group_name)\n",
    "    means.append(vals.mean())\n",
    "    mins_.append(vals.min())\n",
    "    maxs_.append(vals.max())\n",
    "    ns.append(vals.size)\n",
    "\n",
    "means = np.array(means)\n",
    "mins_ = np.array(mins_)\n",
    "maxs_ = np.array(maxs_)\n",
    "\n",
    "# Asymmetric whiskers: [lower, upper]\n",
    "yerr = np.vstack([means - mins_, maxs_ - means])\n",
    "\n",
    "# ----------------------------\n",
    "# Plot\n",
    "# ----------------------------\n",
    "fig, ax = plt.subplots(figsize=(5.5, 2.3), constrained_layout=True)\n",
    "\n",
    "x = np.arange(len(labels))\n",
    "bars = ax.bar(\n",
    "    x, means,\n",
    "    yerr=yerr, capsize=4,\n",
    "    linewidth=0.6, edgecolor=\"black\"\n",
    ")\n",
    "\n",
    "ax.set_ylabel(\"Average Throughput (Gb/s)\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels, rotation=0, ha=\"center\")\n",
    "\n",
    "# Subtle grid for readability\n",
    "ax.yaxis.grid(True, linewidth=0.6, alpha=0.35)\n",
    "ax.set_axisbelow(True)\n",
    "\n",
    "# Annotate mean above each bar (and optionally N)\n",
    "ymax = maxs_.max() if len(maxs_) else 1.0\n",
    "for i, (m, lo, hi, n) in enumerate(zip(means, mins_, maxs_, ns)):\n",
    "    ax.text(\n",
    "        i,\n",
    "        hi + 0.02 * ymax,          # place above max whisker\n",
    "        f\"{m:.2f}\",                # or f\"{m:.2f}\\nN={n}\"\n",
    "        ha=\"center\",\n",
    "        va=\"bottom\"\n",
    "    )\n",
    "\n",
    "# Tighten y-limits to include whiskers nicely\n",
    "ax.set_ylim(0, ymax * 1.12)\n",
    "\n",
    "# Save vector + optional PNG\n",
    "Path(OUT_PDF).parent.mkdir(parents=True, exist_ok=True)\n",
    "fig.savefig(OUT_PDF, bbox_inches=\"tight\")\n",
    "fig.savefig(OUT_PNG, dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b6ff2e-8648-4061-be3b-93437c456ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sender_node.download_file(\"/home/fabric/work/Internship-work/new-exps-paper/fct-cubic-bbr-1.6Gbps.json\",f\"/home/ubuntu/{data_dir}/fct_data.json\")\n",
    "sender_node.download_file(\"/home/fabric/work/Internship-work/new-exps-paper/retrans-cubic-bbr-1.6Gbps.json\",f\"/home/ubuntu/{data_dir}/retransmits_data.json\")\n",
    "sender_node.download_file(\"/home/fabric/work/Internship-work/new-exps-paper/rtt-cubic-bbr-1.6Gbps.json\",f\"/home/ubuntu/{data_dir}/stream_rtt_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bc63a0-092f-4fa9-8660-b93a99cf30fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "receiver_node.download_file(\"/home/fabric/work/Internship-work/cubic-bbr-1.6Gbps-receiver_stats.json\",f\"/home/ubuntu/{data_dir}/final_stream_stats.json\")\n",
    "receiver_node.download_file(\"/home/fabric/work/Internship-work/cubic-bbr-1.6Gbps-receiver_stats-jfi.json\",f\"/home/ubuntu/{data_dir}/fairness_index.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5411e22c-e496-4486-9630-ad8edbfb67cd",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d48d1e-ecf2-436a-9565-3714045fe937",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=\"bbr_single-queue-FQ_1_150_8_100_52_10_100_5_0_0_3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254c0d87-e173-41e3-bcb1-957dbcffc7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sender_node.download_file(f\"/home/fabric/work/Internship-work/L2P2P-QoS/{name}.json\",f\"/home/ubuntu/{name}.json\")\n",
    "receiver_node.download_file(f\"/home/fabric/work/Internship-work/L2P2P-QoS/{name}.txt\",f\"/home/ubuntu/{name}.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e050bff-db4d-49a5-8dfb-470df6015810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# ----------------------------\n",
    "# Paper-style plotting config\n",
    "# ----------------------------\n",
    "plt.rcParams.update({\n",
    "    \"font.size\": 9,\n",
    "    \"axes.titlesize\": 9,\n",
    "    \"xtick.labelsize\": 8,\n",
    "    \"ytick.labelsize\": 8,\n",
    "    \"pdf.fonttype\": 42,\n",
    "    \"ps.fonttype\": 42,\n",
    "    \"axes.linewidth\": 0.8,\n",
    "})\n",
    "\n",
    "TXT_PATH = f\"{name}.txt\"\n",
    "JSON_PATH = f\"{name}.json\"\n",
    "OUT_PDF = f\"{name}_timeseries.pdf\"\n",
    "\n",
    "# ----------------------------\n",
    "# Load goodput\n",
    "# ----------------------------\n",
    "times = []\n",
    "rates = []\n",
    "\n",
    "with open(TXT_PATH) as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\"[SUM]\") and \"receiver\" not in line:\n",
    "            parts = line.split()\n",
    "            start_time = float(parts[1].split(\"-\")[0])\n",
    "            rate = float(parts[-2])\n",
    "            if parts[-1].startswith(\"Gbits\"):\n",
    "                rate *= 1000.0\n",
    "            times.append(start_time)\n",
    "            rates.append(rate / 1000.0)  # Gb/s\n",
    "\n",
    "times = np.array(times)\n",
    "rates = np.array(rates)\n",
    "\n",
    "# ----------------------------\n",
    "# Load JSON metrics\n",
    "# ----------------------------\n",
    "with open(JSON_PATH) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "metrics = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "for interval in data[\"intervals\"]:\n",
    "    for s in interval[\"streams\"]:\n",
    "        sid = s[\"socket\"]\n",
    "        metrics[sid][\"retrans\"].append(s.get(\"retransmits\", 0))\n",
    "        metrics[sid][\"rtt\"].append(s.get(\"rtt\", 0) / 1000)\n",
    "\n",
    "T = max(len(v[\"retrans\"]) for v in metrics.values())\n",
    "t = np.arange(T)  # interval index (time proxy)\n",
    "\n",
    "# ----------------------------\n",
    "# Plot (3 panels)\n",
    "# ----------------------------\n",
    "fig, axes = plt.subplots(1, 3, figsize=(5.4, 2.0), constrained_layout=True)\n",
    "\n",
    "def clean_axis(ax):\n",
    "    ax.grid(True, linewidth=0.6, alpha=0.35)\n",
    "    ax.set_axisbelow(True)\n",
    "\n",
    "# (1) Goodput\n",
    "axes[0].plot(times, rates, linewidth=1.0)\n",
    "axes[0].set_title(\"Goodput (Gb/s)\")\n",
    "axes[0].set_xlabel(\"Time (seconds)\")\n",
    "clean_axis(axes[0])\n",
    "\n",
    "# (2) Retransmissions\n",
    "for sid in metrics:\n",
    "    axes[1].plot(t[:len(metrics[sid][\"retrans\"])],\n",
    "                 metrics[sid][\"retrans\"],\n",
    "                 linewidth=1.0)\n",
    "axes[1].set_title(\"Retransmissions\")\n",
    "axes[1].set_xlabel(\"Time (seconds)\")\n",
    "clean_axis(axes[1])\n",
    "\n",
    "# (3) RTT\n",
    "for sid in metrics:\n",
    "    axes[2].plot(t[:len(metrics[sid][\"rtt\"])],\n",
    "                 metrics[sid][\"rtt\"],\n",
    "                 linewidth=1.0)\n",
    "axes[2].set_title(\"RTT (ms)\")\n",
    "axes[2].set_xlabel(\"Time (seconds)\")\n",
    "clean_axis(axes[2])\n",
    "\n",
    "# ----------------------------\n",
    "# Save\n",
    "# ----------------------------\n",
    "fig.savefig(OUT_PDF, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b600e2-d6f5-485c-a3d2-732c6c102767",
   "metadata": {},
   "source": [
    "### Delete your slice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1500ba-523c-451c-8d30-1326eeccc686",
   "metadata": {},
   "source": [
    "When you finish your experiment, you should delete your slice! The following cells deletes all the resources in your slice, freeing them for other experimenters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0ab4ca-6c1c-4753-b015-dacd41cc7fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice = fablib.get_slice(name=slice_name)\n",
    "fablib.delete_slice(slice_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7625e7a-6d09-47c3-bca3-810e27745d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice should end up in \"Dead\" state\n",
    "# re-run this cell until you see it in \"Dead\" state\n",
    "slice.update()\n",
    "_ = slice.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
